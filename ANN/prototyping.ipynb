{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6caafba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, pytorch_lightning as pl\n",
    "import snntorch.functional as SF\n",
    "from sklearn.metrics import accuracy_score\n",
    "from models import ConvConv\n",
    "# ---------------- constants -------------\n",
    "T, Q = 16, 1.3\n",
    "TH_SHIFT = (Q + 1) / (2 * Q)\n",
    "\n",
    "# -------- 1. Conv2d/Linear â†’ SSPC wrapper --------\n",
    "class SSPCBlock(nn.Module):\n",
    "    def __init__(self, layer, base_in, base_out, max_in, max_out):\n",
    "        super().__init__()\n",
    "        # rescale weights\n",
    "        w = layer.weight.data * (max_in.view(1, -1, 1, 1) / max_out.view(-1, 1, 1, 1))\n",
    "        b = layer.bias.data / max_out\n",
    "        self.W = nn.Parameter(w, requires_grad=False)\n",
    "        self.b = nn.Parameter(b, requires_grad=False)\n",
    "        self.base_in, self.base_out = base_in, base_out\n",
    "        self.register_buffer(\"Vth\", torch.full((w.size(0),), TH_SHIFT))\n",
    "        self.register_buffer(\"fired\", torch.zeros(w.size(0), dtype=torch.bool))\n",
    "        self.register_buffer(\"v\", torch.zeros(w.size(0)))\n",
    "    def forward(self, x_spk):\n",
    "        if self.fired.all():           # no more computation after first spike\n",
    "            return torch.zeros_like(x_spk[:, :self.W.size(0)])\n",
    "        self.v = self.v * self.base_in + torch.einsum('oiwh,b i h w -> b o', self.W, x_spk) + self.b\n",
    "        s = (self.v >= self.Vth) & ~self.fired\n",
    "        self.fired |= s\n",
    "        self.Vth *= self.base_in / self.base_out\n",
    "        return s.float()\n",
    "\n",
    "# -------- 2. Spiking ConvConv -------------\n",
    "class SpikingConvConv(pl.LightningModule):\n",
    "    def __init__(self, input_shape, num_labels, num_conv_filters, size,\n",
    "                 num_hops=10, learning_rate=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # ---- original layers for calibration only -------\n",
    "        self.orig = ConvConv(input_shape, num_labels, num_conv_filters, size)\n",
    "\n",
    "        # ---- gather max_act statistics (offline) -----\n",
    "        max_act = torch.load('max_act.pt')                    # assume pre-computed\n",
    "\n",
    "        # ---- build spiking replicas ----\n",
    "        self.block1 = SSPCBlock(self.orig.conv, 2.0, Q,\n",
    "                                max_act['in0'], max_act['out0'])\n",
    "        self.block2 = SSPCBlock(self.orig.temp_conv[0], Q, Q,\n",
    "                                max_act['out0'], max_act['out1'])\n",
    "        self.block3 = SSPCBlock(self.orig.temp_conv[1], Q, Q,\n",
    "                                max_act['out1'], max_act['out2'])\n",
    "        self.block4 = SSPCBlock(self.orig.temp_conv[3], Q, Q,\n",
    "                                max_act['out2'], max_act['out3'])\n",
    "        self.block5 = SSPCBlock(self.orig.temp_conv[4], Q, Q,\n",
    "                                max_act['out3'], max_act['out4'])\n",
    "        self.fc1    = SSPCBlock(self.orig.fc[0], Q, Q,\n",
    "                                max_act['out4'], max_act['fc0'])\n",
    "        self.fc2    = nn.Linear(128, num_labels, bias=True)   # last layer stays analog\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ---- forward over all phases -------\n",
    "    def forward(self, x):\n",
    "        spikes = SF.rate_to_binary(x, num_steps=T)             # (B,T,seq,feat,1)\n",
    "        B = x.size(0); logits = 0\n",
    "        for t in range(T):\n",
    "            s0 = spikes[:, t].permute(0, 3, 1, 2)             # (B,1,seq,feat)\n",
    "            s1 = self.block1(s0)\n",
    "            s1 = s1.unsqueeze(-1)                             # restore (B,C,H,W)\n",
    "            s2 = self.block2(s1)\n",
    "            s2 = self.block3(s2)\n",
    "            s3 = self.block4(s2)\n",
    "            s3 = self.block5(s3)\n",
    "            flat = s3.flatten(1)\n",
    "            s4 = self.fc1(flat)\n",
    "            logits += self.fc2(s4)                            # accumulate\n",
    "        return logits / T                                     # mean firing score\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        logit = self(x)\n",
    "        loss = self.criterion(logit, y)\n",
    "        self.log(\"loss\", loss);   return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(),\n",
    "                                 lr=self.hparams.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399cb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fokin_snn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
